{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWtCC/jJXpwq3NfAjVPUbu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes evaluate\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes trl tiktoken\n",
        "!pip install -q astor\n",
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9_P-ujuS5j1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095619798,
          "user_tz": -330,
          "elapsed": 184081,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "65893711-9e9c-4f7a-eeb9-50d764a67359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "Successfully installed transformers-4.53.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import ast\n",
        "import astor\n",
        "import re\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All imports done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwJJDFN1Tj7Q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095682670,
          "user_tz": -330,
          "elapsed": 28461,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "a36e4161-6786-4e5a-a65a-4e9a2181c066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09RRXL4kTqAz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095761423,
          "user_tz": -330,
          "elapsed": 28296,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "f3295fc5-cdc6-4a8a-a5d2-a5b28947f397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data with better preprocessing\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/112_time_complexity_dataset.csv\")\n",
        "df = df.drop(columns=[col for col in df.columns if \"Unnamed\" in col])\n",
        "df = df.rename(columns={\"code_snippet\": \"input\", \"time_complexity\": \"output\"})\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "6490EDroTvfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and normalize the data\n",
        "def clean_code(code):\n",
        "    \"\"\"Clean and normalize code snippets\"\"\"\n",
        "    # Remove excessive whitespace\n",
        "    code = re.sub(r'\\n\\s*\\n', '\\n', code)\n",
        "    # Normalize indentation\n",
        "    lines = code.split('\\n')\n",
        "    if lines:\n",
        "        # Remove empty lines at start/end\n",
        "        while lines and not lines[0].strip():\n",
        "            lines.pop(0)\n",
        "        while lines and not lines[-1].strip():\n",
        "            lines.pop()\n",
        "        code = '\\n'.join(lines)\n",
        "    return code.strip()\n"
      ],
      "metadata": {
        "id": "TPWS7e1rUC7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_complexity(complexity):\n",
        "    \"\"\"Normalize complexity notation\"\"\"\n",
        "    complexity = complexity.strip()\n",
        "    # Standardize common variations\n",
        "    complexity = re.sub(r'O\\s*\\(\\s*', 'O(', complexity)\n",
        "    complexity = re.sub(r'\\s*\\)', ')', complexity)\n",
        "    return complexity\n",
        "\n",
        "df['input'] = df['input'].apply(clean_code)\n",
        "df['output'] = df['output'].apply(normalize_complexity)\n",
        "\n",
        "print(f\"Dataset size: {len(df)}\")\n",
        "print(\"Class distribution:\")\n",
        "print(df[\"output\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDM6ZWTvUJ6q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095782120,
          "user_tz": -330,
          "elapsed": 29,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "6c4cceab-44c6-4c3c-b631-2a9259831163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1008\n",
            "Class distribution:\n",
            "output\n",
            "O(log n)      112\n",
            "O(n log n)    112\n",
            "O(n^2)        112\n",
            "O(n!)         112\n",
            "O(2^n)        112\n",
            "O(1)          112\n",
            "O(n^3)        112\n",
            "O(n)          112\n",
            "O(sqrt(n))    112\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced augmentation with better strategies\n",
        "def enhanced_augment_code(code, strategy=\"rename\"):\n",
        "    \"\"\"Multiple code augmentation strategies\"\"\"\n",
        "    try:\n",
        "        tree = ast.parse(code)\n",
        "\n",
        "        if strategy == \"rename_function\":\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.FunctionDef):\n",
        "                    node.name = f\"modified_{node.name}\"\n",
        "\n",
        "        elif strategy == \"rename_variables\":\n",
        "            # Simple variable renaming\n",
        "            var_mapping = {}\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):\n",
        "                    if len(node.id) > 1 and not node.id.startswith('_'):\n",
        "                        var_mapping[node.id] = f\"var_{node.id}\"\n",
        "\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.Name) and node.id in var_mapping:\n",
        "                    node.id = var_mapping[node.id]\n",
        "\n",
        "        elif strategy == \"add_comments\":\n",
        "            # Add a comment by modifying function name\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.FunctionDef):\n",
        "                    node.name = f\"optimized_{node.name}\"\n",
        "\n",
        "        return astor.to_source(tree)\n",
        "    except:\n",
        "        # If AST parsing fails, use simple string modifications\n",
        "        if strategy == \"rename_function\":\n",
        "            return re.sub(r'def (\\w+)', r'def modified_\\1', code)\n",
        "        elif strategy == \"add_comments\":\n",
        "            return re.sub(r'def (\\w+)', r'def optimized_\\1', code)\n",
        "        return code"
      ],
      "metadata": {
        "id": "HPkHS3alUQk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart data augmentation with class balancing\n",
        "def create_balanced_dataset(df, target_samples_per_class=200):\n",
        "    \"\"\"Create a balanced dataset with intelligent augmentation\"\"\"\n",
        "    augmented_data = []\n",
        "    strategies = [\"rename_function\", \"rename_variables\", \"add_comments\"]\n",
        "\n",
        "    for complexity_class in df[\"output\"].unique():\n",
        "        class_data = df[df[\"output\"] == complexity_class].copy()\n",
        "        current_count = len(class_data)\n",
        "\n",
        "        # Add all original samples\n",
        "        for _, row in class_data.iterrows():\n",
        "            augmented_data.append({\n",
        "                \"input\": row[\"input\"],\n",
        "                \"output\": row[\"output\"]\n",
        "            })\n",
        "\n",
        "        # Calculate how many augmented samples needed\n",
        "        target_count = min(target_samples_per_class, current_count * 3)\n",
        "        augment_needed = max(0, target_count - current_count)\n",
        "\n",
        "        # Generate augmented samples\n",
        "        for i in range(augment_needed):\n",
        "            original_row = class_data.iloc[i % len(class_data)]\n",
        "            strategy = strategies[i % len(strategies)]\n",
        "\n",
        "            augmented_code = enhanced_augment_code(original_row[\"input\"], strategy)\n",
        "            augmented_data.append({\n",
        "                \"input\": augmented_code,\n",
        "                \"output\": original_row[\"output\"]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(augmented_data).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Create balanced dataset\n",
        "print(\"Creating balanced dataset...\")\n",
        "df_balanced = create_balanced_dataset(df, target_samples_per_class=180)\n",
        "print(f\"Balanced dataset size: {len(df_balanced)}\")\n",
        "print(\"Balanced class distribution:\")\n",
        "print(df_balanced[\"output\"].value_counts())\n",
        "\n",
        "# Optimized train/validation/test split\n",
        "train_df, temp_df = train_test_split(\n",
        "    df_balanced,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=df_balanced[\"output\"]\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_df[\"output\"]\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "# Convert to datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load model with optimizations\n",
        "model_ckpt = \"Salesforce/codet5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Add padding token if missing\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_ckpt,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "\n",
        "# Optimized LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=16,  # Increased rank for better capacity\n",
        "    lora_alpha=32,  # Balanced alpha\n",
        "    lora_dropout=0.05,  # Reduced dropout\n",
        "    target_modules=[\"q\", \"v\", \"k\", \"o\"],  # Target key attention modules\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(f\"Trainable parameters: {model.get_nb_trainable_parameters()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "303ca72d4eee47c4887ed95f3efcdc77",
            "3de286cb33f346eda917aa6a8a0e04e0",
            "a0fb9e9a63ba463fae0e4e114a440c3c",
            "8e50899b78ae4190beb72c38469d7843",
            "ae9d17f9e5a449f8b217e2711769f845",
            "190ca71e855044d1bebd4a6ba821bdb4",
            "23ddcf8354c24c6494f78122ca1ccf51",
            "c764d904fed74ec1abed5f4c256db7a3",
            "43bfc64996b94364b6fffb9e134452a7",
            "5dbb6140432641ee885dced3b365c07b",
            "fdb3225bb80948e8ae5bfe6f558e4013",
            "2823add5354240c38b1eeb310d61be2d",
            "c093fddd8235400f85e01c0a3394b14c",
            "61c1e06c1b674d97ab1cc5dbfa315d31",
            "53649a59944d49f7aa70a0eb40cd00a2",
            "584e9f1e2af24a2780717c03dad9542a",
            "630dba2848764be1a27a86c30685c668",
            "b6a1550a56ed4e9799bce50481b773e2",
            "54ca2abdc100401e8ce65d2c96bc1cc0",
            "0c3d13f63f0f4efa80bc255f747c2b4e",
            "e7401598d8ea4918b7629924f1bd7753",
            "a50a88c272a643c5b2c15703bc4637a7",
            "17c16b8c793f49f6aca0c2fca98f656a",
            "dbedbc609975488f9c8ae815b9170890",
            "c3f8db83cc114c7db5dceab13bdc4e2e",
            "65cc41eb8039441394159a1469901e6a",
            "47be69430f5b452085ba539818479a4a",
            "7cd22c6274984b6e902f14896d122bf9",
            "3b68aef27de342f6bb5adf983cf8b8a0",
            "31f91722bcba4c279f9d878a17c168a3",
            "ec40fae078d94387a5ae3061e378b5e9",
            "e61c8f5ba65e4bbab83bc6bafb8d46e3",
            "5a175201bf364dcca447256e08ecb552",
            "f07ceff4934e48329bc99d40de8cd4b5",
            "f6478206ebb846d389a9cea0e38c2a64",
            "f63dea1170494f75a2462a700051d311",
            "0e36e23e5ee74eab9684be99c6315e7a",
            "2845941d71b04ad3a8f15d5b5f26fa73",
            "d29868dbc1e24885b9f1aa3fdfc8332a",
            "029e308ae5a249fa9b075e24631677b3",
            "611081a805214515a32f040d4492910a",
            "f69144dbb5d947118c69eee7d66b6161",
            "ab101386d44d49e6acee821eae72de90",
            "7d932883273045c6aff4b402140649e4",
            "c59a5cf4a54c4324b016664b91cc365c",
            "77549194a6364657b967d5ed05d35805",
            "011f23d70237481d95db4c236891f731",
            "b6bd7071f1c340ad86d1c151961686a7",
            "c09680aad6a3490e84adc59296dbc440",
            "75a1ff7b24814fe787e797514ca95d93",
            "f47bd08132ac49a68ee1eb4b11a6d683",
            "58c7a8ff4e7f45728e3d5488c5eac6d2",
            "130a94c1eb634035b4598765eb66dcd3",
            "814e81e67b194980938a27c0a93a1c82",
            "e0f005737be44c97a7d9215d8526b056",
            "6210b855ccf44ebab8835e5c36062d2b",
            "cd2222442dbd479aa908456585898a0d",
            "344aaa06febc490cbeb21bfcfa7a4b58",
            "0d92501c9ff64d9cbb8d1694118e0282",
            "2b16b2940f4347228dc4667d57f05a3e",
            "47c276dd3b7741bcbfe92d142bd8c68c",
            "1de8f1019cab4c7095f09a6b865663ab",
            "f1921524a84842cd935c8084c5ad49f5",
            "f145c837e2d348d3b9bf9ac576679a6d",
            "a2450ca8dbf046119091c3acf9c903ac",
            "2bc31fea75d64a31bc55a76c6baecfc0",
            "e9fb79724df84678bc871a57a28acfd4",
            "06338b2ded3242339d2e571788f6fcae",
            "dee05750ab3943a5996f9b515fdfbe14",
            "72d428ce660e4cb183b20b10995b4b10",
            "7e4d43c772b24e57bb9ef8e32c34c636",
            "3f1d4c91284e44929c44e0f4f11b1b74",
            "a7b9d9f07370498fa72be01ade864801",
            "8d27207b051740fb9db05e9f928c8a88",
            "955d8811c61f49d2b255dbfb8f9d2d9a",
            "0adfa69821e54c4db31204fb263dfbe3",
            "14d39d16801b4a62a5efee3bf6bfb233",
            "fb534e2377f54097863c5415f5baa3b3",
            "80697a22587340e787d1bbfda1a83961",
            "3c8939a5a7944a9fa810ea8d9f3a7b7d",
            "5e7c9c9f78ad4f4dacabe16ad5a7bcb7",
            "3faa82d478264a6aa1e1ecebba0b4f98",
            "bc22632c74004b4c817c747f2d8391d5",
            "25080762efe14719b6e87aebfd70af08",
            "1bfee8f5df7140fa940045e583b83301",
            "eb136d19d27b441a8f97938e3e83840a",
            "ae1b7e5c9c5b44b49a4c4b63f31a96ed",
            "dc6a0995538f4554b7ca06a1e73a8fb2"
          ]
        },
        "id": "4_N6gEYcUXsT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095799539,
          "user_tz": -330,
          "elapsed": 12511,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "f57d5b65-7a43-491e-8146-898ccc4cd96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating balanced dataset...\n",
            "Balanced dataset size: 1548\n",
            "Balanced class distribution:\n",
            "output\n",
            "O(sqrt(n))    180\n",
            "O(n^3)        177\n",
            "O(n!)         175\n",
            "O(2^n)        174\n",
            "O(1)          173\n",
            "O(n log n)    173\n",
            "O(log n)      168\n",
            "O(n)          165\n",
            "O(n^2)        163\n",
            "Name: count, dtype: int64\n",
            "Train: 1083, Val: 232, Test: 233\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "303ca72d4eee47c4887ed95f3efcdc77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2823add5354240c38b1eeb310d61be2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c16b8c793f49f6aca0c2fca98f656a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f07ceff4934e48329bc99d40de8cd4b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c59a5cf4a54c4324b016664b91cc365c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6210b855ccf44ebab8835e5c36062d2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9fb79724df84678bc871a57a28acfd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb534e2377f54097863c5415f5baa3b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: (1179648, 61671936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized preprocessing with format consistency\n",
        "def optimized_preprocess(example):\n",
        "    \"\"\"Optimized preprocessing with better formatting\"\"\"\n",
        "    # Consistent input format\n",
        "    input_text = f\"Analyze time complexity: {example['input']}\"\n",
        "    target_text = example['output']\n",
        "\n",
        "    # Tokenize input with optimal settings\n",
        "    input_encoding = tokenizer(\n",
        "        input_text,\n",
        "        truncation=True,\n",
        "        padding=False,  # Dynamic padding is more efficient\n",
        "        max_length=320,  # Slightly increased for better context\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    # Tokenize target\n",
        "    target_encoding = tokenizer(\n",
        "        target_text,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=16,  # Sufficient for complexity notation\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    # Prepare labels with proper masking\n",
        "    input_encoding[\"labels\"] = [\n",
        "        (token_id if token_id != tokenizer.pad_token_id else -100)\n",
        "        for token_id in target_encoding[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    return input_encoding\n",
        "\n",
        "# Tokenize datasets efficiently\n",
        "print(\"Tokenizing datasets...\")\n",
        "tokenized_train = train_dataset.map(optimized_preprocess, batched=False, num_proc=1)\n",
        "tokenized_val = val_dataset.map(optimized_preprocess, batched=False, num_proc=1)\n",
        "tokenized_test = test_dataset.map(optimized_preprocess, batched=False, num_proc=1)\n",
        "\n",
        "# Optimized data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True,\n",
        "    pad_to_multiple_of=8  # Efficient for GPU\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "e605b130cf934202980a23fa60719760",
            "bc0135fdf5784bdd8105877a1cf51226",
            "f6da17ae23174aa6960bdfa86a1e9969",
            "ae73beb7c26d4dd1a3a9bbff5f321c38",
            "2a8edadcc5104658b5567be66b6aa466",
            "d5389781d46844e39b8594e9499de1c2",
            "343d80a3f6ff4da081edcf94ddd6fee0",
            "3a8e8caf0dea4c2586c1b75ab2430906",
            "55836b8ffcdb43279b72adb4b067bb18",
            "56e0a2899f164eb6b20de83309185f81",
            "0f8d24fd9e244991b717162919618061",
            "b325a5e3c5c94bfc9954d86af0a44252",
            "aef6282d399346d9a2d7f7a287bef44a",
            "b08b5337231d4005a6bfc274b719c013",
            "e32b4e1928d84a5891384854df9d2949",
            "0927cab4f18f4b4aac4d7b26bac34058",
            "477715c80ab340ebbf6693653880d37e",
            "31357c1e34254a298728352a80572afe",
            "c47c4a75795b46479853cad37159d156",
            "65bc18bb70ec4ff28a35481da52fcda2",
            "c4d72d8bebd54b4bbf354f1eaf136e6f",
            "a185cca41e764001aebcb4d591565efb",
            "efb4ee896f2b4ae4a3b519855c395c4b",
            "8d797021aa1a4d46afd6f75f6a7b5f4f",
            "dea2a22d30cc4ce9a891f7ad49e9e16b",
            "0e22c3c2a35b4bb783175f09818339e8",
            "e057e5cb587842c7adb97db8bf916b88",
            "2918738d57964e1da8e6ad66cb6938e3",
            "1661e332e5cf4a10a2b9e9372db16175",
            "df3f552587ed4dee97c22b240aabfb30",
            "d077e59609b547a595e11cf09bc1fc8c",
            "f95e7d2233b84879a0200e3fef4f5e33",
            "5fb834c457cb4a2c993cffa5e0404ead"
          ]
        },
        "id": "CzlU3QtdUrvU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095843470,
          "user_tz": -330,
          "elapsed": 2549,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "a2f6096e-c00c-48aa-f330-e83a74e4e942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1083 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e605b130cf934202980a23fa60719760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b325a5e3c5c94bfc9954d86af0a44252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/233 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efb4ee896f2b4ae4a3b519855c395c4b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced metrics computation\n",
        "def compute_enhanced_metrics(eval_pred):\n",
        "    \"\"\"Enhanced metrics with better accuracy calculation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Handle tuple predictions\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    # Decode predictions\n",
        "    predicted_ids = np.argmax(predictions, axis=-1)\n",
        "    decoded_preds = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Decode labels\n",
        "    labels_filtered = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels_filtered, skip_special_tokens=True)\n",
        "\n",
        "    # Clean and normalize for comparison\n",
        "    def clean_prediction(text):\n",
        "        text = text.strip().lower()\n",
        "        # Remove extra spaces and normalize\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        # Extract O(...) pattern if present\n",
        "        match = re.search(r'o\\([^)]+\\)', text)\n",
        "        if match:\n",
        "            return match.group().upper()\n",
        "        return text.upper()\n",
        "\n",
        "    cleaned_preds = [clean_prediction(pred) for pred in decoded_preds]\n",
        "    cleaned_labels = [clean_prediction(label) for label in decoded_labels]\n",
        "\n",
        "    # Calculate metrics\n",
        "    correct = sum(1 for p, l in zip(cleaned_preds, cleaned_labels) if p == l)\n",
        "    total = len(cleaned_preds)\n",
        "\n",
        "    # Per-class metrics\n",
        "    per_class_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
        "    for pred, label in zip(cleaned_preds, cleaned_labels):\n",
        "        per_class_stats[label][\"total\"] += 1\n",
        "        if pred == label:\n",
        "            per_class_stats[label][\"correct\"] += 1\n",
        "\n",
        "    # Build metrics dictionary\n",
        "    metrics = {\"accuracy\": correct / total if total > 0 else 0.0}\n",
        "\n",
        "    # Add per-class accuracies\n",
        "    for class_name, stats in per_class_stats.items():\n",
        "        if stats[\"total\"] > 0:\n",
        "            class_acc = stats[\"correct\"] / stats[\"total\"]\n",
        "            clean_class_name = re.sub(r'[^a-zA-Z0-9]', '_', class_name)\n",
        "            metrics[f\"acc_{clean_class_name}\"] = class_acc\n",
        "\n",
        "    # Macro average\n",
        "    class_accuracies = [\n",
        "        stats[\"correct\"] / stats[\"total\"]\n",
        "        for stats in per_class_stats.values()\n",
        "        if stats[\"total\"] > 0\n",
        "    ]\n",
        "    metrics[\"macro_avg_accuracy\"] = np.mean(class_accuracies) if class_accuracies else 0.0\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "NTdLgBubU6wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Optimized training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codet5-optimized\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,  # More frequent evaluation\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    per_device_train_batch_size=12,  # Increased batch size\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,  # Effective batch size = 24\n",
        "    num_train_epochs=15,  # Reduced epochs but more efficient\n",
        "    warmup_steps=100,\n",
        "    learning_rate=2e-4,  # Optimized learning rate for LoRA\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=25,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=2,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if available\n",
        "    dataloader_pin_memory=True,\n",
        "    group_by_length=True,  # Efficient batching\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    seed=42,\n",
        "    optim=\"adamw_torch\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "jStxvfxDVI4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create trainer with early stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_enhanced_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hosX--LCVXSN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751095859166,
          "user_tz": -330,
          "elapsed": 26,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "feb25f04-437f-45f9-aa65-db1f0ccf7c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with optimizations\n",
        "print(\"Starting optimized training...\")\n",
        "print(f\"Device: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "gQZ7pZ_3VdIO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751110350858,
          "user_tz": -330,
          "elapsed": 7086129,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "dbe97d6f-13cc-4a50-d101-6b126519b884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimized training...\n",
            "Device: CPU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 1:56:54, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Acc O N  </th>\n",
              "      <th>Acc O 2 N </th>\n",
              "      <th>Acc O N 3 </th>\n",
              "      <th>Acc O Sqrt N </th>\n",
              "      <th>Acc O N Log N </th>\n",
              "      <th>Acc O Log N </th>\n",
              "      <th>Acc O N 2 </th>\n",
              "      <th>Acc O N </th>\n",
              "      <th>Acc O 1 </th>\n",
              "      <th>Macro Avg Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.121100</td>\n",
              "      <td>0.070830</td>\n",
              "      <td>0.823276</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.821184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.126900</td>\n",
              "      <td>0.086317</td>\n",
              "      <td>0.771552</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.768876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.134400</td>\n",
              "      <td>0.094662</td>\n",
              "      <td>0.741379</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.738962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.097900</td>\n",
              "      <td>0.058224</td>\n",
              "      <td>0.849138</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.848509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.101200</td>\n",
              "      <td>0.055988</td>\n",
              "      <td>0.857759</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.855885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.073900</td>\n",
              "      <td>0.048876</td>\n",
              "      <td>0.883621</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.882051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.067900</td>\n",
              "      <td>0.045070</td>\n",
              "      <td>0.866379</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.865628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.064600</td>\n",
              "      <td>0.044463</td>\n",
              "      <td>0.879310</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.878107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.068200</td>\n",
              "      <td>0.039413</td>\n",
              "      <td>0.900862</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.069300</td>\n",
              "      <td>0.039472</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.896056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.037722</td>\n",
              "      <td>0.918103</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.917265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.037619</td>\n",
              "      <td>0.909483</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.908876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.045400</td>\n",
              "      <td>0.037193</td>\n",
              "      <td>0.909483</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.908876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=690, training_loss=0.08118218632711881, metrics={'train_runtime': 7076.7519, 'train_samples_per_second': 2.296, 'train_steps_per_second': 0.098, 'total_flos': 724482373976064.0, 'train_loss': 0.08118218632711881, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_results = trainer.evaluate(eval_dataset=tokenized_test)\n",
        "print(\"Final Test Results:\")\n",
        "for key, value in test_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "aNPBwb01VmOw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751115069506,
          "user_tz": -330,
          "elapsed": 62393,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "38a22c8f-8103-42e4-acb7-34cd2188137b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 1:18:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Results:\n",
            "eval_loss: 0.0579\n",
            "eval_accuracy: 0.8755\n",
            "eval_acc_O_N_3_: 1.0000\n",
            "eval_acc_O_LOG_N_: 0.8400\n",
            "eval_acc_O_N__: 0.7778\n",
            "eval_acc_O_2_N_: 0.9231\n",
            "eval_acc_O_SQRT_N_: 0.9630\n",
            "eval_acc_O_N_2_: 0.7500\n",
            "eval_acc_O_N_LOG_N_: 0.7692\n",
            "eval_acc_O_N_: 0.8400\n",
            "eval_acc_O_1_: 1.0000\n",
            "eval_macro_avg_accuracy: 0.8737\n",
            "eval_runtime: 62.2921\n",
            "eval_samples_per_second: 3.7400\n",
            "eval_steps_per_second: 0.2410\n",
            "epoch: 15.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the optimized model\n",
        "trainer.save_model(\"./codet5-final\")\n",
        "tokenizer.save_pretrained(\"./codet5-final\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6rHQqhXVwr7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751115111236,
          "user_tz": -330,
          "elapsed": 531,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "682d6fba-c24a-4702-8dee-7fe5a03c6c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./codet5-final/tokenizer_config.json',\n",
              " './codet5-final/special_tokens_map.json',\n",
              " './codet5-final/vocab.json',\n",
              " './codet5-final/merges.txt',\n",
              " './codet5-final/added_tokens.json',\n",
              " './codet5-final/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick inference test\n",
        "def test_inference(code_snippet):\n",
        "    \"\"\"Test the trained model on a code snippet\"\"\"\n",
        "    input_text = f\"Analyze time complexity: {code_snippet}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=320)\n",
        "\n",
        "    # Move input tensors to the same device as the model\n",
        "    device = model.device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"].to(device),\n",
        "            attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "            max_length=16,\n",
        "            num_beams=3,\n",
        "            temperature=0.1,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return prediction.strip()\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    # O(1)\n",
        "    \"def get_first_element(arr):\\n    return arr[0]\",\n",
        "\n",
        "    # O(log n)\n",
        "    \"def binary_search(arr, target):\\n    low, high = 0, len(arr) - 1\\n    while low <= high:\\n        mid = (low + high) // 2\\n        if arr[mid] == target:\\n            return mid\\n        elif arr[mid] < target:\\n            low = mid + 1\\n        else:\\n            high = mid - 1\\n    return -1\",\n",
        "\n",
        "    # O(n)\n",
        "    \"def find_element(arr, target):\\n    for i in arr:\\n        if i == target:\\n            return True\\n    return False\",\n",
        "\n",
        "    # O(n log n)\n",
        "    \"def merge_sort(arr):\\n    if len(arr) > 1:\\n        mid = len(arr) // 2\\n        L = arr[:mid]\\n        R = arr[mid:]\\n        merge_sort(L)\\n        merge_sort(R)\\n        i = j = k = 0\\n        while i < len(L) and j < len(R):\\n            if L[i] < R[j]:\\n                arr[k] = L[i]\\n                i += 1\\n            else:\\n                arr[k] = R[j]\\n                j += 1\\n            k += 1\\n        while i < len(L):\\n            arr[k] = L[i]\\n            i += 1\\n            k += 1\\n        while j < len(R):\\n            arr[k] = R[j]\\n            j += 1\\n            k += 1\",\n",
        "\n",
        "    # O(n^2)\n",
        "    \"def bubble_sort(arr):\\n    n = len(arr)\\n    for i in range(n):\\n        for j in range(0, n-i-1):\\n            if arr[j] > arr[j+1]:\\n                arr[j], arr[j+1] = arr[j+1], arr[j]\",\n",
        "\n",
        "    # O(n^3)\n",
        "    \"def triple_loop(arr):\\n    n = len(arr)\\n    for i in range(n):\\n        for j in range(n):\\n            for k in range(n):\\n                arr[i] += arr[j] + arr[k]\",\n",
        "\n",
        "    # O(n!)\n",
        "    \"def permutations(arr):\\n    if len(arr) == 0:\\n        return [[]]\\n    res = []\\n    for i in range(len(arr)):\\n        rest = arr[:i] + arr[i+1:]\\n        for p in permutations(rest):\\n            res.append([arr[i]] + p)\\n    return res\",\n",
        "\n",
        "    # O(2^n)\n",
        "    \"def fib(n):\\n    if n <= 1:\\n        return n\\n    return fib(n-1) + fib(n-2)\",\n",
        "\n",
        "    # O(sqrt(n))\n",
        "    \"def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\",\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "print(\"\\nTesting inference:\")\n",
        "for example in test_examples:\n",
        "    prediction = test_inference(example)\n",
        "    print(f\"Code: {example[:50]}...\")\n",
        "    print(f\"Prediction: {prediction}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\nOptimization Summary:\")\n",
        "print(\"\u2713 Enhanced data augmentation with class balancing\")\n",
        "print(\"\u2713 Optimized LoRA configuration (r=16)\")\n",
        "print(\"\u2713 Better preprocessing and tokenization\")\n",
        "print(\"\u2713 Increased batch size with gradient accumulation\")\n",
        "print(\"\u2713 Mixed precision training (if GPU available)\")\n",
        "print(\"\u2713 Early stopping to prevent overfitting\")\n",
        "print(\"\u2713 Cosine learning rate schedule with restarts\")\n",
        "print(\"\u2713 Dynamic padding for efficiency\")\n",
        "print(\"\u2713 Improved metrics calculation\")\n",
        "print(\"\u2713 Reduced epochs with better convergence\")\n",
        "\n",
        "print(f\"\\nExpected improvements:\")\n",
        "print(f\"\u2022 Accuracy: 60-75% (vs previous ~45%)\")\n",
        "print(f\"\u2022 Training time: Similar or faster due to optimizations\")\n",
        "print(f\"\u2022 Better class balance and performance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlWWX65fV4n9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751115123672,
          "user_tz": -330,
          "elapsed": 5497,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "ab1b4b9a-a63d-47df-f095-bbb402a5f1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing inference:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def get_first_element(arr):\n",
            "    return arr[0]...\n",
            "Prediction: O(1)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def binary_search(arr, target):\n",
            "    low, high = 0,...\n",
            "Prediction: O(log n)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def find_element(arr, target):\n",
            "    for i in arr:\n",
            " ...\n",
            "Prediction: O(n)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def merge_sort(arr):\n",
            "    if len(arr) > 1:\n",
            "        ...\n",
            "Prediction: O(n log n)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def bubble_sort(arr):\n",
            "    n = len(arr)\n",
            "    for i i...\n",
            "Prediction: O(n^2)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def triple_loop(arr):\n",
            "    n = len(arr)\n",
            "    for i i...\n",
            "Prediction: O(n^3)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def permutations(arr):\n",
            "    if len(arr) == 0:\n",
            "     ...\n",
            "Prediction: O(n)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: def fib(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    re...\n",
            "Prediction: O(2^n)\n",
            "--------------------------------------------------\n",
            "Code: def is_prime(n):\n",
            "    if n <= 1:\n",
            "        return Fal...\n",
            "Prediction: O(sqrt(n))\n",
            "--------------------------------------------------\n",
            "\n",
            "Optimization Summary:\n",
            "\u2713 Enhanced data augmentation with class balancing\n",
            "\u2713 Optimized LoRA configuration (r=16)\n",
            "\u2713 Better preprocessing and tokenization\n",
            "\u2713 Increased batch size with gradient accumulation\n",
            "\u2713 Mixed precision training (if GPU available)\n",
            "\u2713 Early stopping to prevent overfitting\n",
            "\u2713 Cosine learning rate schedule with restarts\n",
            "\u2713 Dynamic padding for efficiency\n",
            "\u2713 Improved metrics calculation\n",
            "\u2713 Reduced epochs with better convergence\n",
            "\n",
            "Expected improvements:\n",
            "\u2022 Accuracy: 60-75% (vs previous ~45%)\n",
            "\u2022 Training time: Similar or faster due to optimizations\n",
            "\u2022 Better class balance and performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you're using Trainer API\n",
        "trainer.save_model('/content/drive/MyDrive/finetuned_model_final')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/finetuned_model_final')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T278c9ObK7Ll",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751115158566,
          "user_tz": -330,
          "elapsed": 595,
          "user": {
            "displayName": "Prakrati Prajapati 4-Yr B.Tech.: Mechanical Engg., IIT(BHU)",
            "userId": "10897345780295592232"
          }
        },
        "outputId": "d9d5b706-19dd-473a-e8ad-090a9ffab673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/finetuned_model_final/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/finetuned_model_final/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/finetuned_model_final/vocab.json',\n",
              " '/content/drive/MyDrive/finetuned_model_final/merges.txt',\n",
              " '/content/drive/MyDrive/finetuned_model_final/added_tokens.json',\n",
              " '/content/drive/MyDrive/finetuned_model_final/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}